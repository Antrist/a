package au.edu.wehi.socrates;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;

import org.apache.commons.cli.OptionBuilder;

import au.edu.wehi.socrates.util.SAMRecordMateCoordinateComparator;
import au.edu.wehi.socrates.util.SAMRecordSummary;

import net.sf.picard.analysis.CollectInsertSizeMetrics;
import net.sf.picard.analysis.InsertSizeMetrics;
import net.sf.picard.analysis.MetricAccumulationLevel;
import net.sf.picard.analysis.directed.InsertSizeMetricsCollector;
import net.sf.picard.cmdline.CommandLineProgram;
import net.sf.picard.cmdline.Option;
import net.sf.picard.cmdline.StandardOptionDefinitions;
import net.sf.picard.cmdline.Usage;
import net.sf.picard.filter.AggregateFilter;
import net.sf.picard.filter.DuplicateReadFilter;
import net.sf.picard.filter.FailsVendorReadQualityFilter;
import net.sf.picard.filter.FilteringIterator;
import net.sf.picard.filter.SamRecordFilter;
import net.sf.picard.io.IoUtil;
import net.sf.picard.metrics.MetricsFile;
import net.sf.picard.util.Log;
import net.sf.picard.util.ProgressLogger;
import net.sf.samtools.BAMRecordCodec;
import net.sf.samtools.SAMException;
import net.sf.samtools.SAMFileHeader;
import net.sf.samtools.SAMFileReader;
import net.sf.samtools.SAMFileWriter;
import net.sf.samtools.SAMFileWriterFactory;
import net.sf.samtools.SAMRecord;
import net.sf.samtools.SAMRecordIterator;
import net.sf.samtools.SAMSequenceDictionary;
import net.sf.samtools.SAMFileHeader.SortOrder;
import net.sf.samtools.util.CloseableIterator;
import net.sf.samtools.util.CollectionUtil;
import net.sf.samtools.util.SortingCollection;

public class GenerateDirectedBreakpoints extends CommandLineProgram {

    private static final String PROGRAM_VERSION = "0.1";

    // The following attributes define the command-line arguments
    @Usage
    public String USAGE = getStandardUsagePreamble() + "Generated directed breakpoints." + PROGRAM_VERSION;

    @Option(doc = "Coordinate sorted input file containing reads supporting putative structural variations",
            optional = false,
            shortName = StandardOptionDefinitions.INPUT_SHORT_NAME)
    public File INPUT;
    @Option(doc = "DP and OEA read pairs sorted by coordinate of mapped mate read.",
            optional = false,
            shortName = "MCI")
    public File MATE_COORDINATE_INPUT = null;    
    @Option(doc = "Directed single-ended breakpoints. A placeholder contig is output as the breakpoint partner.",
            optional = false,
            shortName=StandardOptionDefinitions.OUTPUT_SHORT_NAME)
    public File VCF_OUTPUT;
    @Option(doc = "FASTQ of reference strand sequences of putative breakpoints excluding anchored bases. These sequences are used to align breakpoints",
            optional = false,
            shortName = "FQ")
    public File FASTQ_OUTPUT = null;
    @Option(doc = "Picard metrics file generated by ExtractEvidence",
            optional = true)
    public File METRICS = null;
    @Option
    @Option(doc = "Minimum alignment mapq", optional=true)
    public int MIN_MAPQ = 5;
    @Option(doc = "Length threshold of long soft-clip", optional=true)
    public int LONG_SC_LEN = 25;
    @Option(doc = "Minimum alignment percent identity to reference. Takes values in the range 0-100.", optional=true)
    public int MIN_PERCENT_IDENTITY = 95;
    @Option(doc = "Minimum average base quality score of soft clipped sequence", optional=true)
    public int MIN_LONG_SC_BASE_QUALITY = 5;
    private Log log = Log.getInstance(GenerateDirectedBreakpoints.class);
    @Override
	protected int doWork() {
    	SAMFileReader.setDefaultValidationStringency(SAMFileReader.ValidationStringency.SILENT);
    	try {
    		if (METRICS == null) {
    			METRICS = FileNamingConvention.GetMetrics(INPUT);
    		}
    		IoUtil.assertFileIsReadable(METRICS);
    		
	    	final SAMFileReader reader = new SAMFileReader(INPUT);
	    	final SAMFileHeader header = reader.getFileHeader();
	    	final SAMSequenceDictionary dictionary = header.getSequenceDictionary();
	    	
	    	
	    	final InsertSizeMetricsCollector metrics = new InsertSizeMetricsCollector(
	    			CollectionUtil.makeSet(MetricAccumulationLevel.ALL_READS, MetricAccumulationLevel.READ_GROUP),
					header.getReadGroups(),
					// match CollectInsertSizeMetrics defaults
					 new CollectInsertSizeMetrics().MINIMUM_PCT,
					 new CollectInsertSizeMetrics().HISTOGRAM_WIDTH,
					 new CollectInsertSizeMetrics().DEVIATIONS);
	    	
	    	final SAMFileWriter[] writers = new SAMFileWriter[dictionary.size() + 1];
	    	final SAMFileWriter[] matewriters = new SAMFileWriter[dictionary.size() + 1];
	    	final ArrayList<SortingCollection<SAMRecord>> matecollection = new ArrayList<SortingCollection<SAMRecord>>();
	    	final SAMFileHeader svHeader = header.clone();
	    	svHeader.setSortOrder(SortOrder.coordinate);
	    	final SAMFileHeader mateHeader = header.clone();
	    	mateHeader.setSortOrder(SortOrder.unsorted);
	    	final SAMFileWriterFactory factory = new SAMFileWriterFactory();
	    	if (PER_CHR) {
	    		for (int i = 0; i < dictionary.size(); i++) {
	    			writers[i] = factory.makeBAMWriter(svHeader, true, FileNamingConvention.GetSVBamForChr(INPUT, dictionary.getSequence(i).getSequenceName()));
	    			matewriters[i] = factory.makeBAMWriter(mateHeader, false, FileNamingConvention.GetMateBamForChr(INPUT, dictionary.getSequence(i).getSequenceName()));
	    			matecollection.add(SortingCollection.newInstance(SAMRecord.class, new BAMRecordCodec(mateHeader), new SAMRecordMateCoordinateComparator(),
	    					// TODO: allocate buffers according to sequence lengths instead of equal space to every chr
	    					MAX_RECORDS_IN_RAM / dictionary.size(),
	    					TMP_DIR));
	    		}
				writers[dictionary.size()] = factory.makeBAMWriter(svHeader, true, FileNamingConvention.GetSVBamForChr(INPUT, "unmapped"));
	    	} else {
	    		// all writers map to the same one
	    		writers[0] = factory.makeBAMWriter(svHeader, true, FileNamingConvention.GetSVBam(INPUT));
				matewriters[0] = factory.makeBAMWriter(mateHeader, false, FileNamingConvention.GetMateBam(INPUT));
				matecollection.add(SortingCollection.newInstance(SAMRecord.class, new BAMRecordCodec(matewriters[0].getFileHeader()), new SAMRecordMateCoordinateComparator(), MAX_RECORDS_IN_RAM, TMP_DIR));
				for (int i = 1; i < dictionary.size() + 1; i++) {
					writers[i] = writers[0];
					matewriters[i] = matewriters[0];
				}
	    	}
	    	// Traverse the input file
	    	final ProgressLogger progress = new ProgressLogger(log);
			final SAMRecordIterator iter = reader.iterator();
			iter.assertSorted(SortOrder.coordinate);
			while (iter.hasNext()) {
				SAMRecord record = iter.next();
				int offset = record.getReadUnmappedFlag() ? dictionary.size() : record.getReferenceIndex();
				boolean sc = SAMRecordSummary.isAlignmentSoftClipped(record);
				boolean badpair = SAMRecordSummary.isPartOfNonReferenceReadPair(record);
				if (sc || badpair) {
					writers[offset].addAlignment(record);
				}
				if (badpair) {
					matecollection.get(record.getMateReferenceIndex()).add(record);
				}
				metrics.acceptRecord(record, null);
				progress.record(record);
			}
			reader.close();
			metrics.finish();
			final MetricsFile<InsertSizeMetrics, Integer> serialisedMetrics = getMetricsFile();
			metrics.addAllLevelsToFile(serialisedMetrics);
			serialisedMetrics.write(FileNamingConvention.GetMetrics(INPUT));
			for (int i = 0; i < dictionary.size(); i++) {
				if (writers[i] != null) {
					writers[i].close();
					writers[i] = null;
				}
			}
			if (PER_CHR) {
				for (int i = 0; i < dictionary.size(); i++) {
					// TODO: this can be multi-threaded
					matewriters[i].setProgressLogger(new ProgressLogger(log));
					writeToFile(matecollection.get(i), matewriters[i]);
					matewriters[i].close();
					matecollection.set(i, null);
				}
				
			} else {
				matewriters[0].setProgressLogger(new ProgressLogger(log));
				writeToFile(matecollection.get(0), matewriters[0]);
				matewriters[0].close();
			}
			matecollection.clear();
    	} catch (IOException e) {
    		throw new RuntimeException(e);
    	}
        return 0;
    	SAMRecordEvidenceProcessorOrchestrator orch;
    }
	public static void main(String[] argv) {
        System.exit(new GenerateDirectedBreakpoints().instanceMain(argv));
    }
}
