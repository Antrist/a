package au.edu.wehi.socrates;

import htsjdk.samtools.reference.ReferenceSequenceFile;
import htsjdk.samtools.reference.ReferenceSequenceFileFactory;
import htsjdk.samtools.util.IOUtil;
import htsjdk.samtools.util.Log;
import htsjdk.samtools.util.ProgressLogger;
import htsjdk.variant.variantcontext.VariantContext;
import htsjdk.variant.variantcontext.writer.VariantContextWriter;
import htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder;
import htsjdk.variant.vcf.VCFHeader;

import java.io.File;
import java.io.IOException;
import java.util.Iterator;
import java.util.List;
import java.util.PriorityQueue;

import com.google.common.collect.Lists;

import picard.cmdline.Option;
import picard.cmdline.StandardOptionDefinitions;
import picard.cmdline.Usage;
import au.edu.wehi.socrates.vcf.VcfConstants;

/**
 * Clusters evidence that supports a common breakpoint together
 * @author Daniel Cameron
 *
 */
public class ClusterEvidence extends CommandLineProgram {

    private static final String PROGRAM_VERSION = "0.1";

    // The following attributes define the command-line arguments
    @Usage
    public String USAGE = getStandardUsagePreamble() + "Calls breakpoints between the two given chromosomes" +
    		"based on the evidence provided" + PROGRAM_VERSION;
    @Option(doc = "Input BAM file.",
            optional = false,
            shortName = StandardOptionDefinitions.INPUT_SHORT_NAME)
    public File INPUT;
    @Option(doc = "Chromosome to process. This argument can be supplied twice to process interchromosomal",
            optional = true,
            shortName = "CHR")
    public List<String> CHROMSOME;
    @Option(doc = "Breakpoint calls in VCF format",
            optional = true,
            shortName= StandardOptionDefinitions.OUTPUT_SHORT_NAME)
    public File OUTPUT;
    @Option(doc="Reference used for alignment",
    		optional = false,
    		shortName=StandardOptionDefinitions.REFERENCE_SHORT_NAME)
    public File REFERENCE;
    @Option(doc = "Picard metrics file generated by ExtractEvidence",
            optional = true)
    public File METRICS = null;
    private Log log = Log.getInstance(ClusterEvidence.class);
    @Override
	protected int doWork() {
    	try {
    		if (METRICS == null) {
    			METRICS = FileNamingConvention.getMetrics(INPUT);
    		}
    		if (CHROMSOME == null) {
    			CHROMSOME = Lists.newArrayList();
    		}
    		if (OUTPUT == null) {
    			switch (CHROMSOME.size()) {
    			case 0:
    				OUTPUT = FileNamingConvention.getRawCallVcf(INPUT);
    				break;
    			case 1:
    				OUTPUT = FileNamingConvention.getRawCallVcf(INPUT, CHROMSOME.get(0), CHROMSOME.get(0));
    				break;
    			case 2:
    				OUTPUT = FileNamingConvention.getRawCallVcf(INPUT, CHROMSOME.get(0), CHROMSOME.get(1));
    				break;
    			}
    		}
    		IOUtil.assertFileIsReadable(REFERENCE);
    		IOUtil.assertFileIsReadable(METRICS);
    		IOUtil.assertFileIsWritable(OUTPUT);
    		
	    	final RelevantMetrics metrics = new RelevantMetrics(METRICS);
	    	final ReferenceSequenceFile reference = ReferenceSequenceFileFactory.getReferenceSequenceFile(REFERENCE);
	    	final ProcessingContext processContext = new ProcessingContext(reference, metrics);
			
			// TODO: add filtering parameters so we only process evidence between 1 and 2 
			// (@see DirectedEvidenceChromosomePairFilter)
			EvidenceClusterProcessor processor;
			log.info("Loading minimal evidence set");
			if (CHROMSOME.size() == 0) {
				processor = new EvidenceClusterProcessor(processContext);
				addEvidence(processor, allEvidence(processContext));
			} else if (CHROMSOME.size() == 1) {
				processor = new EvidenceClusterSubsetProcessor(processContext, processContext.getDictionary().getSequenceIndex(CHROMSOME.get(0)), processContext.getDictionary().getSequenceIndex(CHROMSOME.get(0)));
				addEvidence(processor, evidenceForChr(processContext, CHROMSOME.get(0)));
			} else if (CHROMSOME.size() == 2) {
				processor = new EvidenceClusterSubsetProcessor(processContext, processContext.getDictionary().getSequenceIndex(CHROMSOME.get(0)), processContext.getDictionary().getSequenceIndex(CHROMSOME.get(1)));
				addEvidence(processor, evidenceForChr(processContext, CHROMSOME.get(0)));
				addEvidence(processor, evidenceForChr(processContext, CHROMSOME.get(1)));
			} else {
				throw new RuntimeException("CHROMSOME argument supplied too many times");
			}
			log.info("Calling maximal cliques");
			final ProgressLogger writeProgress = new ProgressLogger(log);
			final VariantContextWriter vcfWriter = new VariantContextWriterBuilder()
				.setOutputFile(OUTPUT)
				.setReferenceDictionary(processContext.getDictionary())
				.build();
			final VCFHeader vcfHeader = new VCFHeader();
			vcfHeader.setSequenceDictionary(processContext.getDictionary());
			VcfConstants.addHeaders(vcfHeader);
			vcfWriter.writeHeader(vcfHeader);
			
			// Write out both sides of the breakend in order
			// since the first breakend is always the lower genomic coordinate
			// this will result in in-order output
			PriorityQueue<BreakpointSummary> highEnd = new PriorityQueue<BreakpointSummary>(1024, BreakendSummary.ByStartEnd);
			Iterator<BreakendSummary> it = processor.iterator();
			while (it.hasNext()) {
				BreakendSummary loc = it.next();
				if (loc instanceof BreakpointSummary) {
					// Add the remote side of the call
					highEnd.add(((BreakpointSummary)loc).remoteBreakpoint());
				}
				while (!highEnd.isEmpty() && BreakendSummary.ByStartEnd.compare(highEnd.peek(), loc) < 0) {
					// write remote calls that are before here
					writeCall(processContext, vcfWriter, highEnd.poll(), writeProgress);
				}
				// write call
				writeCall(processContext, vcfWriter, loc, writeProgress);
			}
			// flush out the remote calls that we haven't written yet
			while (!highEnd.isEmpty()) {
				writeCall(processContext, vcfWriter, highEnd.poll(), writeProgress);
			}
			vcfWriter.close();
    	} catch (IOException e) {
    		log.error(e);
    		throw new RuntimeException(e);
    	}
        return 0;
    }
	private void writeCall(final ProcessingContext processContext,
			final VariantContextWriter vcfWriter, BreakendSummary loc, ProgressLogger progress) {
		VariantContextDirectedBreakpointBuilder builder = new VariantContextDirectedBreakpointBuilder(processContext)
			.breakend(loc, null)
			.evidence(loc.evidence);
		// Issue: we've lost all our extended info including the untemplated sequence
		VariantContext vc = builder.make(); 
		vcfWriter.add(vc);
		progress.record(vc.getChr(), vc.getStart());
	}
    private static void addEvidence(EvidenceClusterProcessor processor, DirectedEvidenceFileIterator evidence) {
    	while (evidence.hasNext()) {
			processor.addEvidence(evidence.next());
		}
    	evidence.close();
    }
	private DirectedEvidenceFileIterator evidenceForChr(final ProcessingContext processContext, final String chr) throws IOException {
		final DirectedEvidenceFileIterator dei1 = new DirectedEvidenceFileIterator(
				processContext,
				getSamReaderFactory(),
				ensureFileExists(FileNamingConvention.getSVBamForChr(INPUT, chr)),
				ensureFileExists(FileNamingConvention.getMateBamForChr(INPUT, chr)),
				ensureFileExists(FileNamingConvention.getRealignmentBamForChr(INPUT, chr)),
				ensureFileExists(FileNamingConvention.getBreakendVcfForChr(INPUT, chr)));
		return dei1;
	}
	private DirectedEvidenceFileIterator allEvidence(final ProcessingContext processContext) throws IOException {
		final DirectedEvidenceFileIterator dei1 = new DirectedEvidenceFileIterator(
				processContext,
				getSamReaderFactory(),
				ensureFileExists(FileNamingConvention.getSVBam(INPUT)),
				ensureFileExists(FileNamingConvention.getMateBam(INPUT)),
				ensureFileExists(FileNamingConvention.getRealignmentBam(INPUT)),
				ensureFileExists(FileNamingConvention.getBreakendVcf(INPUT)));
		return dei1;
	}
	public static void main(String[] argv) {
        System.exit(new ClusterEvidence().instanceMain(argv));
    }
}